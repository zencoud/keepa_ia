import openai
import logging
import re
from django.conf import settings
from typing import Dict, Any, Optional, List
from datetime import datetime
import json

logger = logging.getLogger(__name__)


class OpenAIService:
    """Servicio para interactuar con la API de OpenAI"""
    
    def __init__(self):
        """Inicializa el cliente de OpenAI con la API key"""
        self.api_key = settings.OPENAI_API_KEY
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY no est√° configurada en settings")
        
        self.client = openai.OpenAI(api_key=self.api_key)
    
    def generate_price_summary(self, product_data: Dict[str, Any]) -> Optional[str]:
        """
        Genera un resumen inteligente del historial de precios usando OpenAI
        
        Args:
            product_data: Dict con informaci√≥n del producto incluyendo price_history
            
        Returns:
            String con el resumen generado o None si hay error
        """
        try:
            # Extraer datos relevantes
            title = product_data.get('title', 'Producto')
            price_history = product_data.get('price_history', {})
            current_price_new = product_data.get('current_price_new')
            current_price_amazon = product_data.get('current_price_amazon')
            rating = product_data.get('rating')
            review_count = product_data.get('review_count')
            sales_rank = product_data.get('sales_rank_current')
            
            # Verificar que haya datos de precios
            if not price_history or all(not prices.get('prices') for prices in price_history.values()):
                logger.warning("No hay suficiente historial de precios para generar resumen")
                return None
            
            # Preparar datos de precios para el prompt
            price_data_summary = self._prepare_price_data_for_prompt(price_history)
            
            # Construir el prompt
            prompt = self._build_prompt(
                title=title,
                price_data_summary=price_data_summary,
                current_price_new=current_price_new,
                current_price_amazon=current_price_amazon,
                rating=rating,
                review_count=review_count,
                sales_rank=sales_rank
            )
            
            logger.info(f"Generando resumen de IA para producto: {title[:50]}...")
            
            # Llamar a OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Eres un analista de precios de Amazon experto y amigable. "
                            "Tu trabajo es ayudar a los usuarios a entender los patrones de precios "
                            "y tomar decisiones inteligentes de compra. Habla de forma natural y conversacional, "
                            "como si fueras su asesor personal de compras. Usa insights inteligentes, "
                            "identifica tendencias, y da recomendaciones estrat√©gicas. "
                            "Puedes usar emojis sutilmente (m√°ximo 2-3) para hacer el texto m√°s visual. "
                            "S√© conciso pero informativo (3-5 oraciones)."
                        )
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=300,
                top_p=0.9,
            )
            
            summary = response.choices[0].message.content.strip()
            logger.info("Resumen de IA generado exitosamente")
            
            return summary
            
        except Exception as e:
            logger.error(f"Error generando resumen con OpenAI: {e}")
            return None
    
    def _prepare_price_data_for_prompt(self, price_history: Dict[str, Any]) -> str:
        """
        Prepara un resumen de los datos de precios para incluir en el prompt
        
        Args:
            price_history: Dict con el historial de precios
            
        Returns:
            String con resumen de precios formateado
        """
        summary_parts = []
        
        for price_type in ['NEW', 'AMAZON', 'USED']:
            if price_type in price_history:
                price_data = price_history[price_type]
                prices = price_data.get('prices', [])
                times = price_data.get('formatted_times', [])
                
                if prices and len(prices) > 0:
                    # Convertir de centavos a d√≥lares
                    prices_dollars = [p / 100 for p in prices if p > 0]
                    
                    if prices_dollars:
                        min_price = min(prices_dollars)
                        max_price = max(prices_dollars)
                        avg_price = sum(prices_dollars) / len(prices_dollars)
                        current_price = prices_dollars[-1]
                        
                        # Calcular tendencia (comparar primeros 30% vs √∫ltimos 30%)
                        n = len(prices_dollars)
                        if n >= 6:
                            early_avg = sum(prices_dollars[:n//3]) / (n//3)
                            recent_avg = sum(prices_dollars[-n//3:]) / (n//3)
                            change_pct = ((recent_avg - early_avg) / early_avg) * 100
                            trend = "subi√≥" if change_pct > 5 else "baj√≥" if change_pct < -5 else "se mantuvo estable"
                        else:
                            trend = "datos limitados"
                        
                        type_label = {
                            'NEW': 'Nuevo',
                            'AMAZON': 'Amazon',
                            'USED': 'Usado'
                        }.get(price_type, price_type)
                        
                        summary_parts.append(
                            f"{type_label}: ${current_price:.2f} actual, "
                            f"promedio ${avg_price:.2f}, rango ${min_price:.2f}-${max_price:.2f}, "
                            f"tendencia: {trend}"
                        )
        
        return "\n".join(summary_parts) if summary_parts else "Datos de precios limitados"
    
    def _build_prompt(
        self,
        title: str,
        price_data_summary: str,
        current_price_new: Optional[int],
        current_price_amazon: Optional[int],
        rating: Optional[float],
        review_count: Optional[int],
        sales_rank: Optional[int]
    ) -> str:
        """
        Construye el prompt para OpenAI
        
        Args:
            title: T√≠tulo del producto
            price_data_summary: Resumen de datos de precios
            current_price_new: Precio actual nuevo (en centavos)
            current_price_amazon: Precio actual Amazon (en centavos)
            rating: Calificaci√≥n del producto
            review_count: N√∫mero de rese√±as
            sales_rank: Sales rank actual
            
        Returns:
            String con el prompt completo
        """
        # Construir informaci√≥n del producto
        product_info = f"Producto: {title}\n\n"
        
        # Agregar precios actuales
        if current_price_new:
            product_info += f"Precio actual (Nuevo): ${current_price_new / 100:.2f}\n"
        if current_price_amazon:
            product_info += f"Precio actual (Amazon): ${current_price_amazon / 100:.2f}\n"
        
        # Agregar m√©tricas adicionales
        if rating:
            product_info += f"Calificaci√≥n: {rating:.1f} estrellas\n"
        if review_count:
            product_info += f"Rese√±as: {review_count:,}\n"
        if sales_rank:
            product_info += f"Sales Rank: #{sales_rank:,}\n"
        
        product_info += f"\nHistorial de Precios:\n{price_data_summary}\n"
        
        prompt = (
            f"{product_info}\n"
            "Analiza el historial de precios y genera un resumen amigable y conversacional. "
            "Incluye: precio promedio, tendencias identificadas, cambios significativos, "
            "y una recomendaci√≥n estrat√©gica sobre cu√°ndo comprar. "
            "Habla como un analista experto dando consejos a un amigo. "
            "Mant√©n el tono natural y profesional."
        )
        
        return prompt
    
    def chat_with_product(
        self, 
        user_message: str,
        conversation_history: list,
        product_data: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Chat conversacional con contexto completo de Keepa
        
        Args:
            user_message: Pregunta del usuario
            conversation_history: Lista de mensajes previos [{"role": "user/assistant", "content": "..."}]
            product_data: Datos COMPLETOS del producto (con todos los histories)
            
        Returns:
            Respuesta de la IA
        """
        try:
            # Construir system prompt con contexto completo
            system_prompt = self._build_chat_system_prompt(product_data)
            
            # Construir lista de mensajes completa
            messages = [
                {"role": "system", "content": system_prompt}
            ]
            
            # Agregar historial de conversaci√≥n (limitado a √∫ltimos 10 mensajes)
            if conversation_history:
                messages.extend(conversation_history[-10:])
            
            # Agregar mensaje actual del usuario
            messages.append({"role": "user", "content": user_message})
            
            logger.info(f"Generando respuesta de chat con {len(messages)} mensajes")
            
            # Llamar a OpenAI API con temperatura m√°s alta para conversaci√≥n
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.8,  # M√°s creativo para chat
                max_tokens=500,  # Aumentado para respuestas con an√°lisis temporal
                top_p=0.9,
            )
            
            answer = response.choices[0].message.content.strip()
            logger.info("Respuesta de chat generada exitosamente")
            
            return answer
            
        except Exception as e:
            logger.error(f"Error en chat con OpenAI: {e}")
            return "Lo siento, tuve un problema generando la respuesta. Por favor intenta de nuevo."
    
    def _build_chat_system_prompt(self, product_data: Optional[Dict[str, Any]] = None) -> str:
        """
        Construye el system prompt para el chat con TODOS los datos de Keepa
        
        Args:
            product_data: Datos completos del producto o None si no hay producto
            
        Returns:
            String con el system prompt completo
        """
        base_prompt = (
            "Eres Keepa AI, un asistente experto en an√°lisis de precios de Amazon. "
            "Tu trabajo es ayudar a los usuarios a tomar decisiones inteligentes de compra "
            "bas√°ndote en datos hist√≥ricos de Keepa.\n\n"
            "IMPORTANTE: Usa formato Markdown cuando presentes listas, tablas o informaci√≥n estructurada:\n"
            "- Usa listas con vi√±etas (-) o numeradas (1.) cuando enumeres elementos\n"
            "- Usa **negritas** para destacar informaci√≥n importante\n"
            "- Usa tablas markdown cuando presentes datos comparativos\n"
            "- Usa encabezados (##) para secciones cuando sea apropiado\n"
            "- Mant√©n el formato markdown limpio y legible\n\n"
        )
        
        if not product_data:
            # Modo general sin producto espec√≠fico
            return base_prompt + (
                "Actualmente no hay un producto espec√≠fico seleccionado. "
                "Puedes responder preguntas generales sobre Amazon, precios, o ayudar "
                "al usuario a navegar. S√© amigable y ofrece tu ayuda."
            )
        
        # Construir contexto completo del producto
        product_context = "DATOS COMPLETOS DEL PRODUCTO:\n"
        product_context += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        # Informaci√≥n b√°sica
        product_context += "üì¶ PRODUCTO\n"
        product_context += f"- T√≠tulo: {product_data.get('title', 'N/A')}\n"
        product_context += f"- ASIN: {product_data.get('asin', 'N/A')}\n"
        if product_data.get('brand'):
            product_context += f"- Marca: {product_data.get('brand')}\n"
        if product_data.get('categories'):
            cats = ', '.join(product_data.get('categories', [])[:3])
            product_context += f"- Categor√≠as: {cats}\n"
        
        # Precios
        product_context += "\nüíµ PRECIOS\n"
        if product_data.get('current_price_new'):
            product_context += f"- Precio actual (Nuevo): ${product_data.get('current_price_new') / 100:.2f}\n"
        if product_data.get('current_price_amazon'):
            product_context += f"- Precio actual (Amazon): ${product_data.get('current_price_amazon') / 100:.2f}\n"
        if product_data.get('current_price_used'):
            product_context += f"- Precio actual (Usado): ${product_data.get('current_price_used') / 100:.2f}\n"
        
        # Analizar historial de precios si existe
        price_history = product_data.get('price_history', {})
        if price_history and price_history.get('NEW', {}).get('prices'):
            prices = [p / 100 for p in price_history['NEW']['prices']]
            if prices:
                product_context += f"- Precio promedio hist√≥rico: ${sum(prices) / len(prices):.2f}\n"
                product_context += f"- Rango hist√≥rico: ${min(prices):.2f} - ${max(prices):.2f}\n"
        
        # Sales Rank (ventas y popularidad)
        product_context += "\nüìà VENTAS & POPULARIDAD\n"
        if product_data.get('sales_rank_current'):
            product_context += f"- Sales Rank actual: #{product_data.get('sales_rank_current'):,}\n"
        
        sales_rank_history = product_data.get('sales_rank_history', {})
        if sales_rank_history and sales_rank_history.get('values'):
            values = sales_rank_history['values']
            if len(values) >= 2:
                # Comparar primero vs √∫ltimo para tendencia
                early = sum(values[:len(values)//3]) / (len(values)//3) if len(values) >= 3 else values[0]
                recent = sum(values[-len(values)//3:]) / (len(values)//3) if len(values) >= 3 else values[-1]
                if early > recent * 1.1:
                    trend = "mejorando significativamente (rank bajando = m√°s ventas)"
                elif early < recent * 0.9:
                    trend = "empeorando (rank subiendo = menos ventas)"
                else:
                    trend = "estable"
                product_context += f"- Tendencia de ventas: {trend}\n"
        
        # Rating y rese√±as
        product_context += "\n‚≠ê REPUTACI√ìN & CALIDAD\n"
        if product_data.get('rating'):
            product_context += f"- Rating actual: {product_data.get('rating'):.1f} estrellas\n"
        if product_data.get('review_count'):
            product_context += f"- Total de rese√±as: {product_data.get('review_count'):,}\n"
        
        rating_history = product_data.get('rating_history', {})
        if rating_history and rating_history.get('values'):
            values = rating_history['values']
            if len(values) >= 2:
                early = sum(values[:len(values)//3]) / (len(values)//3) if len(values) >= 3 else values[0]
                recent = sum(values[-len(values)//3:]) / (len(values)//3) if len(values) >= 3 else values[-1]
                if recent > early + 0.2:
                    trend = "mejorando (calidad en alza)"
                elif recent < early - 0.2:
                    trend = "empeorando (calidad en baja)"
                else:
                    trend = "estable"
                product_context += f"- Tendencia de calidad: {trend}\n"
        
        reviews_data = product_data.get('reviews_data', {})
        if reviews_data and reviews_data.get('rating_distribution'):
            dist = reviews_data['rating_distribution']
            total = sum(dist.values())
            if total > 0:
                positive = (dist.get(5, 0) + dist.get(4, 0)) / total * 100
                product_context += f"- Reviews positivas (4-5‚òÖ): {positive:.0f}%\n"
        
        # üìä DATOS HIST√ìRICOS DETALLADOS (con fechas)
        product_context += "\n\nüìä HISTORIAL DETALLADO (√öltimos datos disponibles):\n"
        product_context += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        
        # Historial de PRECIOS con fechas
        if price_history:
            for price_type in ['NEW', 'AMAZON', 'USED']:
                if price_type in price_history:
                    data = price_history[price_type]
                    prices = data.get('prices', [])
                    times = data.get('formatted_times', [])
                    
                    if prices and times and len(prices) == len(times):
                        # Tomar √∫ltimos 15 puntos (aprox 3-6 meses dependiendo frecuencia)
                        recent_count = min(15, len(prices))
                        recent_prices = prices[-recent_count:]
                        recent_times = times[-recent_count:]
                        
                        type_label = {'NEW': 'Nuevo', 'AMAZON': 'Amazon', 'USED': 'Usado'}.get(price_type, price_type)
                        product_context += f"\nüè∑Ô∏è Precios ({type_label}) - √öltimos {recent_count} registros:\n"
                        
                        for i in range(len(recent_prices)):
                            if recent_prices[i] > 0:
                                price_usd = recent_prices[i] / 100
                                product_context += f"  ‚Ä¢ {recent_times[i]}: ${price_usd:.2f}\n"
        
        # Historial de SALES RANK con fechas
        if sales_rank_history and sales_rank_history.get('values') and sales_rank_history.get('formatted_times'):
            values = sales_rank_history['values']
            times = sales_rank_history['formatted_times']
            
            if len(values) == len(times) and len(values) > 0:
                recent_count = min(15, len(values))
                recent_values = values[-recent_count:]
                recent_times = times[-recent_count:]
                
                product_context += f"\nüìä Sales Rank - √öltimos {recent_count} registros:\n"
                for i in range(len(recent_values)):
                    if recent_values[i] > 0:
                        product_context += f"  ‚Ä¢ {recent_times[i]}: #{recent_values[i]:,}\n"
        
        # Historial de RATING con fechas
        if rating_history and rating_history.get('values') and rating_history.get('formatted_times'):
            values = rating_history['values']
            times = rating_history['formatted_times']
            
            if len(values) == len(times) and len(values) > 0:
                recent_count = min(10, len(values))
                recent_values = values[-recent_count:]
                recent_times = times[-recent_count:]
                
                product_context += f"\n‚≠ê Rating - √öltimos {recent_count} registros:\n"
                for i in range(len(recent_values)):
                    if recent_values[i] > 0:
                        product_context += f"  ‚Ä¢ {recent_times[i]}: {recent_values[i]:.1f} estrellas\n"
        
        # Instrucciones para la IA
        instructions = (
            "\n\nüìã INSTRUCCIONES:\n"
            "- Tienes acceso a DATOS HIST√ìRICOS COMPLETOS con FECHAS ESPEC√çFICAS\n"
            "- Cuando te pidan an√°lisis temporal (ej: √∫ltimos 3 meses), usa las fechas del historial\n"
            "- Identifica tendencias, picos, ca√≠das y patrones temporales\n"
            "- Cita fechas y valores espec√≠ficos cuando sea relevante\n"
            "- S√© conversacional y amigable, como un asesor personal\n"
            "- Da recomendaciones honestas basadas en los datos temporales\n"
            "- Responde en 3-5 oraciones (conciso pero completo)\n"
            "- Puedes usar emojis sutilmente (1-2 m√°ximo)\n"
        )
        
        return base_prompt + product_context + instructions
    
    def detect_best_sellers_intent(self, user_message: str) -> Optional[Dict[str, Any]]:
        """
        Detecta si el usuario pregunta sobre best sellers de una categor√≠a
        
        Args:
            user_message: Mensaje del usuario
            
        Returns:
            Dict con 'intent' ('best_sellers' o None), 'category_query' (t√©rmino de categor√≠a o None)
            O None si no hay intenci√≥n de best sellers
        """
        try:
            prompt = f"""
Analiza el siguiente mensaje del usuario y determina si pregunta sobre best sellers, m√°s vendidos, o productos m√°s populares de una categor√≠a.

Mensaje del usuario: "{user_message}"

PATRONES DE DETECCI√ìN (sin√≥nimos en espa√±ol):
- "best sellers", "best seller", "bestsellers"
- "m√°s vendidos", "mas vendidos", "m√°s vendido", "mas vendido"
- "top ventas", "top venta"
- "productos m√°s vendidos", "productos mas vendidos"
- "mejores ventas", "mejor venta"
- "top productos", "top producto"
- "ranking de ventas", "ranking ventas"
- "productos m√°s populares", "productos mas populares"
- "m√°s populares", "mas populares"
- "top", "top ventas", "top venta"

Si el usuario pregunta sobre best sellers, extrae tambi√©n la categor√≠a mencionada (ej: "laptops", "libros", "electr√≥nica", "computadoras", etc.)

Responde SOLO con un JSON v√°lido en este formato:
{{
    "intent": "best_sellers" o null,
    "category_query": "t√©rmino de categor√≠a extra√≠do del mensaje o null",
    "specific_request": "descripci√≥n breve de lo que pidi√≥ espec√≠ficamente"
}}

Ejemplos:
- "mu√©strame best sellers de laptops" ‚Üí {{"intent": "best_sellers", "category_query": "laptops", "specific_request": "best sellers de laptops"}}
- "¬øcu√°les son los m√°s vendidos de libros?" ‚Üí {{"intent": "best_sellers", "category_query": "libros", "specific_request": "m√°s vendidos de libros"}}
- "top ventas de electr√≥nica" ‚Üí {{"intent": "best_sellers", "category_query": "electr√≥nica", "specific_request": "top ventas de electr√≥nica"}}
- "productos m√°s vendidos en computadoras" ‚Üí {{"intent": "best_sellers", "category_query": "computadoras", "specific_request": "productos m√°s vendidos en computadoras"}}
- "¬øcu√°l es el precio?" ‚Üí {{"intent": null, "category_query": null, "specific_request": "pregunta sobre precio"}}
- "¬øc√≥mo est√° el producto?" ‚Üí {{"intent": null, "category_query": null, "specific_request": "pregunta general"}}
- "best sellers" (sin categor√≠a) ‚Üí {{"intent": "best_sellers", "category_query": null, "specific_request": "best sellers"}}

IMPORTANTE: 
- Responde SOLO con el JSON, sin texto adicional.
- Si detectas intenci√≥n de best sellers pero no hay categor√≠a clara, establece category_query como null.
- Extrae la categor√≠a mencionada en el mensaje, incluso si est√° en espa√±ol.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # Modelo peque√±o y r√°pido para detecci√≥n
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Eres un clasificador de intenciones experto. Analiza mensajes y determina si el usuario "
                            "pregunta sobre best sellers, m√°s vendidos, o productos m√°s populares de una categor√≠a. "
                            "Detecta sin√≥nimos en espa√±ol como: best sellers, m√°s vendidos, top ventas, productos m√°s vendidos, "
                            "mejores ventas, top productos, ranking de ventas, productos m√°s populares. "
                            "Extrae tambi√©n la categor√≠a mencionada si existe. "
                            "Responde siempre con JSON v√°lido."
                        )
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.2,  # Muy baja temperatura para detecci√≥n consistente
                max_tokens=200,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content.strip())
            
            # Manejar casos donde OpenAI retorna "null" como string o el valor null real
            intent_value = result.get('intent')
            if intent_value == 'null' or intent_value is None or (isinstance(intent_value, str) and intent_value.lower() == 'null'):
                logger.info(f"[BEST_SELLERS] No se detect√≥ intenci√≥n de best sellers: {result}")
                return None
            
            # Si detecta intenci√≥n de best sellers, retornar el resultado
            if intent_value == 'best_sellers':
                # Limpiar category_query si es null
                category_query = result.get('category_query')
                if category_query in [None, 'null', '']:
                    category_query = None
                else:
                    category_query = str(category_query).strip()
                
                result['category_query'] = category_query
                logger.info(f"[BEST_SELLERS] ‚úì Intenci√≥n de best sellers detectada: {result}")
                return result
            
            logger.info(f"[BEST_SELLERS] No se detect√≥ intenci√≥n de best sellers: {result}")
            return None
            
        except Exception as e:
            logger.error(f"[BEST_SELLERS] Error detectando intenci√≥n de best sellers: {e}")
            # En caso de error, retornar None
            return None
    
    def detect_product_mention(self, user_message: str) -> Optional[Dict[str, Any]]:
        """
        Detecta si el usuario menciona un producto espec√≠fico en su mensaje
        
        Args:
            user_message: Mensaje del usuario
            
        Returns:
            Dict con 'product_name' (nombre del producto mencionado) o None si no se detecta
            {
                'product_name': 'Canary Flex Indoor/Outdoor',
                'confidence': 'high' | 'medium' | 'low'
            }
        """
        try:
            prompt = f"""
Analiza el siguiente mensaje del usuario y determina si menciona un producto espec√≠fico por nombre.

Mensaje del usuario: "{user_message}"

Tu tarea es identificar si el usuario est√° preguntando sobre un producto espec√≠fico mencionado por su nombre (ej: "Canary Flex Indoor", "Arlo Adjustable Mount", etc.).

Ejemplos de mensajes que mencionan productos:
- "sobre canary flex indoor que precio tiene?"
- "¬øcu√°nto cuesta el Arlo Adjustable Mount?"
- "informaci√≥n del EZVIZ Husky HD"
- "Canary Flex Indoor/Outdoor precio"
- "dame detalles del Netgear Vma1100"

Ejemplos de mensajes que NO mencionan productos espec√≠ficos:
- "¬øcu√°l es el precio?" (sin mencionar producto)
- "¬øc√≥mo est√° el producto?" (sin mencionar producto)
- "mu√©strame best sellers" (pregunta sobre categor√≠a)
- "productos m√°s vendidos" (pregunta general)

Responde SOLO con un JSON v√°lido en este formato:
{{
    "has_product_mention": true o false,
    "product_name": "nombre del producto extra√≠do o null",
    "confidence": "high" o "medium" o "low" o null
}}

IMPORTANTE:
- Si detectas un producto mencionado, extrae su nombre completo o parcial (ej: "Canary Flex Indoor", "Arlo Adjustable")
- Si no hay menci√≥n clara de producto, establece has_product_mention como false
- confidence indica qu√© tan seguro est√°s de que es un producto espec√≠fico
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # Modelo peque√±o y r√°pido para detecci√≥n
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Eres un analizador de mensajes experto. Tu trabajo es identificar si el usuario menciona "
                            "un producto espec√≠fico por su nombre en su mensaje. Extrae el nombre del producto si existe. "
                            "Responde siempre con JSON v√°lido."
                        )
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.2,  # Baja temperatura para detecci√≥n consistente
                max_tokens=200,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content.strip())
            
            # Verificar si detect√≥ menci√≥n de producto
            has_mention = result.get('has_product_mention', False)
            if not has_mention:
                logger.info(f"[PRODUCT_DETECTION] No se detect√≥ menci√≥n de producto: {result}")
                return None
            
            product_name = result.get('product_name')
            if not product_name or product_name in [None, 'null', '']:
                logger.info(f"[PRODUCT_DETECTION] Se detect√≥ menci√≥n pero no se extrajo nombre: {result}")
                return None
            
            product_name = str(product_name).strip()
            confidence = result.get('confidence', 'medium')
            
            logger.info(f"[PRODUCT_DETECTION] ‚úì Producto detectado: '{product_name}' (confidence: {confidence})")
            
            return {
                'product_name': product_name,
                'confidence': confidence
            }
            
        except Exception as e:
            logger.error(f"[PRODUCT_DETECTION] Error detectando producto: {e}")
            # En caso de error, retornar None
            return None
    
    def detect_document_intent(self, user_message: str) -> Optional[Dict[str, str]]:
        """
        Detecta si el usuario quiere generar un documento usando IA (PASO 1)
        
        Args:
            user_message: Mensaje del usuario
            
        Returns:
            Dict con 'intent' ('document' o None) y 'format' ('pdf', 'csv', etc. o None)
            O None si no hay intenci√≥n de documento
        """
        try:
            prompt = f"""
Analiza el siguiente mensaje del usuario y determina si quiere generar un documento/archivo/reporte/exportar datos.

Mensaje del usuario: "{user_message}"

PATRONES DE DETECCI√ìN AMPLIADOS:
- Generaci√≥n: "genera", "crear", "hazme", "dame", "exporta", "descarga"
- Formatos: "pdf", "excel", "csv", "txt", "json", "markdown", "documento", "reporte", "informe", "archivo"
- An√°lisis: "an√°lisis completo", "reporte detallado", "informe de", "documento con todos los datos"
- Exportaci√≥n: "exportar", "descargar", "guardar como", "obtener archivo"

Responde SOLO con un JSON v√°lido en este formato:
{{
    "intent": "document" o null,
    "format": "pdf" o "xlsx" o "csv" o "txt" o "json" o "md" o null,
    "specific_request": "descripci√≥n breve de lo que pidi√≥ espec√≠ficamente"
}}

Ejemplos EXPANDIDOS:
- "genera un pdf" ‚Üí {{"intent": "document", "format": "pdf", "specific_request": "generar pdf"}}
- "quiero un excel con los precios" ‚Üí {{"intent": "document", "format": "xlsx", "specific_request": "excel con precios"}}
- "descarga el an√°lisis" ‚Üí {{"intent": "document", "format": null, "specific_request": "descargar an√°lisis"}}
- "hazme un reporte completo" ‚Üí {{"intent": "document", "format": null, "specific_request": "reporte completo"}}
- "exporta todos los datos" ‚Üí {{"intent": "document", "format": null, "specific_request": "exportar todos los datos"}}
- "dame un informe con todo el historial" ‚Üí {{"intent": "document", "format": null, "specific_request": "informe con historial completo"}}
- "crear documento con an√°lisis" ‚Üí {{"intent": "document", "format": null, "specific_request": "documento con an√°lisis"}}
- "¬øcu√°l es el precio?" ‚Üí {{"intent": null, "format": null, "specific_request": "pregunta sobre precio"}}
- "¬øc√≥mo est√° el producto?" ‚Üí {{"intent": null, "format": null, "specific_request": "pregunta general"}}

IMPORTANTE: Responde SOLO con el JSON, sin texto adicional.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # Modelo peque√±o y r√°pido para detecci√≥n
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Eres un clasificador de intenciones experto. Analiza mensajes y determina si el usuario "
                            "quiere generar, exportar, descargar o crear un documento/archivo/reporte. "
                            "Detecta patrones como: genera, crea, exporta, descarga, dame, hazme, reporte, informe, an√°lisis, documento. "
                            "Responde siempre con JSON v√°lido."
                        )
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.2,  # Muy baja temperatura para detecci√≥n consistente
                max_tokens=150,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content.strip())
            
            # Manejar casos donde OpenAI retorna "null" como string o el valor null real
            intent_value = result.get('intent')
            if intent_value == 'null' or intent_value is None or (isinstance(intent_value, str) and intent_value.lower() == 'null'):
                logger.info(f"[PASO 1] No se detect√≥ intenci√≥n de documento: {result}")
                return None
            
            # Si detecta intenci√≥n de documento, retornar el resultado
            if intent_value == 'document':
                # Limpiar format si es null
                if result.get('format') in [None, 'null', '']:
                    result['format'] = None
                logger.info(f"[PASO 1] ‚úì Intenci√≥n de documento detectada: {result}")
                return result
            
            logger.info(f"[PASO 1] No se detect√≥ intenci√≥n de documento: {result}")
            return None
            
        except Exception as e:
            logger.error(f"[PASO 1] Error detectando intenci√≥n de documento: {e}")
            # En caso de error, fallback a detecci√≥n manual b√°sica
            return None
    
    def confirm_document_generation(self, user_message: str, product_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Segundo filtro: Valida la intenci√≥n con contexto del producto y confirma qu√© datos incluir (PASO 2)
        
        Args:
            user_message: Mensaje del usuario
            product_data: Datos completos del producto para contexto
            
        Returns:
            Dict con confirmaci√≥n y campos a incluir, o None si no se confirma
            {
                "confirmed": True,
                "include_fields": {
                    "basic_info": True,
                    "price_history": True/False,
                    "rating_history": True/False,
                    "sales_rank_history": True/False,
                    "reviews_data": True/False
                },
                "user_focus": "descripci√≥n de lo que el usuario quiere ver"
            }
        """
        try:
            # Preparar resumen del producto disponible
            product_summary = f"""
PRODUCTO DISPONIBLE:
- T√≠tulo: {product_data.get('title', 'N/A')[:100]}
- ASIN: {product_data.get('asin', 'N/A')}
- Marca: {product_data.get('brand', 'N/A')}
- Precio actual: ${product_data.get('current_price_new', 0) / 100:.2f}
- Rating: {product_data.get('rating', 0):.1f}‚≠ê ({product_data.get('review_count', 0):,} rese√±as)

DATOS HIST√ìRICOS DISPONIBLES:
- Historial de precios: {'‚úì Disponible' if product_data.get('price_history') else '‚úó No disponible'}
- Historial de calificaciones: {'‚úì Disponible' if product_data.get('rating_history') else '‚úó No disponible'}
- Historial de sales rank: {'‚úì Disponible' if product_data.get('sales_rank_history') else '‚úó No disponible'}
- Datos de rese√±as: {'‚úì Disponible' if product_data.get('reviews_data') else '‚úó No disponible'}
"""
            
            prompt = f"""
Contexto: Un usuario est√° viendo un producto en Keepa IA y ha hecho una solicitud.

{product_summary}

Solicitud del usuario: "{user_message}"

Analiza si el usuario REALMENTE quiere generar un documento con los datos de este producto.
Si confirmas que S√ç, determina qu√© informaci√≥n debe incluirse.

REGLA IMPORTANTE: Si el usuario pide "todo", "completo", "an√°lisis completo", o "todos los datos",
incluye TODOS los historiales disponibles sin excepci√≥n.

Responde SOLO con un JSON v√°lido en este formato:
{{
    "confirmed": true o false,
    "include_fields": {{
        "basic_info": true,
        "price_history": true o false,
        "rating_history": true o false,
        "sales_rank_history": true o false,
        "reviews_data": true o false
    }},
    "user_focus": "breve descripci√≥n del enfoque del usuario"
}}

Ejemplos:
- "genera pdf completo" ‚Üí {{"confirmed": true, "include_fields": {{"basic_info": true, "price_history": true, "rating_history": true, "sales_rank_history": true, "reviews_data": true}}, "user_focus": "documento completo con todos los datos"}}
- "solo los precios en excel" ‚Üí {{"confirmed": true, "include_fields": {{"basic_info": true, "price_history": true, "rating_history": false, "sales_rank_history": false, "reviews_data": false}}, "user_focus": "historial de precios"}}
- "¬øcu√°nto cuesta?" ‚Üí {{"confirmed": false, "include_fields": {{}}, "user_focus": "solo pregunta sobre precio"}}

IMPORTANTE: Responde SOLO con el JSON, sin texto adicional.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # Modelo mini para validaci√≥n r√°pida
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Eres un validador experto. Tu trabajo es confirmar si el usuario quiere generar un documento "
                            "y determinar exactamente qu√© informaci√≥n debe incluirse. "
                            "Si el usuario pide 'todo', 'completo' o 'an√°lisis completo', SIEMPRE incluye todos los historiales. "
                            "Responde siempre con JSON v√°lido."
                        )
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.2,  # Baja temperatura para consistencia
                max_tokens=250,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content.strip())
            
            # Verificar confirmaci√≥n
            if not result.get('confirmed', False):
                logger.info(f"[PASO 2] Generaci√≥n de documento NO confirmada: {result.get('user_focus', 'N/A')}")
                return None
            
            logger.info(f"[PASO 2] ‚úì Generaci√≥n confirmada. Campos a incluir: {result.get('include_fields', {})}")
            logger.info(f"[PASO 2] Enfoque del usuario: {result.get('user_focus', 'N/A')}")
            
            return result
            
        except Exception as e:
            logger.error(f"[PASO 2] Error confirmando generaci√≥n de documento: {e}")
            # En caso de error, asumir que se confirma con todos los datos
            return {
                "confirmed": True,
                "include_fields": {
                    "basic_info": True,
                    "price_history": True,
                    "rating_history": True,
                    "sales_rank_history": True,
                    "reviews_data": True
                },
                "user_focus": "documento completo (fallback por error)"
            }
    
    def generate_document_content(self, product_data: Dict[str, Any], document_type: str = "general", user_request: str = None) -> str:
        """
        Genera contenido flexible en Markdown seg√∫n la solicitud del usuario
        
        Args:
            product_data: Datos completos del producto
            document_type: Tipo de documento (legacy, ahora se usa user_request principalmente)
            user_request: Solicitud espec√≠fica del usuario que determina qu√© incluir
            
        Returns:
            String con contenido en Markdown
        """
        try:
            # Construir prompt flexible basado en la solicitud del usuario
            prompt = self._build_flexible_document_prompt(product_data, user_request)
            
            logger.info(f"[PASO 3] Generando contenido flexible para documento. Solicitud: {user_request}")
            logger.info(f"[PASO 3] Tama√±o del prompt: {len(prompt)} caracteres")
            
            # Llamar a OpenAI con respuesta en Markdown (PASO 3)
            # Detectar si necesita m√°s tokens (historiales completos)
            asks_for_full_history = user_request and any(word in user_request.lower() for word in ['historial', 'hist√≥rico', 'historia', 'completo', 'todos', 'todas', 'todo', 'completa'])
            # Aumentar significativamente max_tokens para historiales completos
            max_tokens = 8000 if asks_for_full_history else 4000
            
            logger.info(f"[PASO 3] Generando contenido Markdown con max_tokens={max_tokens} (historial completo: {asks_for_full_history})")
            logger.info(f"[PASO 3] Llamando a OpenAI API con modelo gpt-4o...")
            
            response = self.client.chat.completions.create(
                model="gpt-4o",  # Modelo con mayor capacidad para generar contenido extenso
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Eres un generador de contenido Markdown experto que trabaja con datos de Amazon/Keepa. "
                            "COMPRENDES que NO puedes generar archivos PDF/Excel/CSV directamente (eres una IA de lenguaje), "
                            "por lo que tu trabajo es generar contenido estructurado en Markdown que ser√° convertido t√©cnicamente.\n\n"
                            "REGLAS CR√çTICAS:\n"
                            "1. Genera EXACTAMENTE lo que el usuario pidi√≥, nada m√°s, nada menos\n"
                            "2. Si pide una tabla, COPIA TODA la tabla del contexto con TODAS las filas\n"
                            "3. Si pide 'historial completo' o 'todos los datos', incluye TODOS los registros disponibles\n"
                            "4. NO resumas, NO limites filas, NO omitas datos\n"
                            "5. NO inventes datos - usa SOLO los del contexto proporcionado\n"
                            "6. NO incluyas delimitadores de c√≥digo (```markdown o ```)\n"
                            "7. Usa formato Markdown puro: tablas (| |), t√≠tulos (# ##), listas (-, *)\n"
                            "8. Termina siempre con: '---\\n*Generado por Keepa AI*'\n\n"
                            "IMPORTANTE: Si el contexto tiene una tabla con 500 filas, DEBES copiar las 500 filas completas."
                        )
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.2,  # Muy determinista para copiar datos exactos
                max_tokens=max_tokens,
            )
            
            markdown_content = response.choices[0].message.content.strip()
            logger.info(f"[PASO 3] Respuesta recibida de OpenAI: {len(markdown_content)} caracteres")
            
            # Limpiar bloques de c√≥digo Markdown que OpenAI a veces agrega
            markdown_content = self._clean_markdown_content(markdown_content)
            logger.info(f"[PASO 3] Contenido limpiado: {len(markdown_content)} caracteres")
            
            logger.info("[PASO 3] ‚úì Contenido Markdown generado exitosamente")
            return markdown_content
            
        except Exception as e:
            logger.error(f"[PASO 3] Error generando contenido de documento: {e}")
            logger.error(f"[PASO 3] Tipo de error: {type(e).__name__}")
            logger.error(f"[PASO 3] User request: {user_request}")
            import traceback
            logger.error(f"[PASO 3] Traceback completo:\n{traceback.format_exc()}")
            # Retornar contenido b√°sico en Markdown
            return self._get_fallback_markdown(product_data, user_request)
    
    def _clean_markdown_content(self, content: str) -> str:
        """
        Limpia el contenido Markdown removiendo bloques de c√≥digo y delimitadores
        
        Args:
            content: Contenido Markdown crudo
            
        Returns:
            Contenido Markdown limpio
        """
        # Remover bloques de c√≥digo markdown (```markdown ... ```)
        content = re.sub(r'```markdown\s*\n', '', content, flags=re.IGNORECASE)
        content = re.sub(r'```md\s*\n', '', content, flags=re.IGNORECASE)
        content = re.sub(r'```\s*$', '', content, flags=re.MULTILINE)
        content = re.sub(r'^```\s*\n', '', content, flags=re.MULTILINE)
        
        # Remover bloques de c√≥digo gen√©ricos si quedan
        lines = content.split('\n')
        cleaned_lines = []
        skip_next = False
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            
            # Detectar inicio de bloque de c√≥digo
            if stripped.startswith('```') and ('markdown' in stripped.lower() or 'md' in stripped.lower() or len(stripped) == 3):
                skip_next = True
                continue
            
            # Detectar fin de bloque de c√≥digo
            if skip_next and stripped == '```':
                skip_next = False
                continue
            
            if not skip_next:
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines).strip()
    
    def _build_flexible_document_prompt(self, product_data: Dict[str, Any], user_request: str = None) -> str:
        """
        Construye un prompt flexible que adapta el contenido seg√∫n la solicitud del usuario
        
        Args:
            product_data: Datos completos del producto
            user_request: Solicitud espec√≠fica del usuario
            
        Returns:
            String con el prompt flexible
        """
        # Obtener datos b√°sicos
        title = product_data.get('title', 'Producto')
        asin = product_data.get('asin', 'N/A')
        brand = product_data.get('brand', 'N/A')
        current_price_new = product_data.get('current_price_new', 0) / 100 if product_data.get('current_price_new') else None
        current_price_amazon = product_data.get('current_price_amazon', 0) / 100 if product_data.get('current_price_amazon') else None
        current_price_used = product_data.get('current_price_used', 0) / 100 if product_data.get('current_price_used') else None
        rating = product_data.get('rating', 0)
        review_count = product_data.get('review_count', 0)
        sales_rank_current = product_data.get('sales_rank_current')
        
        # Obtener TODOS los campos adicionales
        binding = product_data.get('binding', 'N/A')
        color = product_data.get('color', 'N/A')
        availability_amazon = product_data.get('availability_amazon', 0)
        categories = product_data.get('categories', [])
        category_tree = product_data.get('category_tree', [])
        image_url = product_data.get('image_url', 'N/A')
        last_updated = product_data.get('last_updated', 'N/A')
        created_at = product_data.get('created_at', 'N/A')
        queried_by = product_data.get('queried_by', 'N/A')
        
        # Construir contexto completo de datos disponibles - ABSOLUTAMENTE TODOS
        context = f"""
# DATOS COMPLETOS DEL PRODUCTO:

## Informaci√≥n B√°sica
- **T√≠tulo**: {title}
- **ASIN**: {asin}
- **Marca**: {brand}
- **Categor√≠a/Binding**: {binding}
- **Color**: {color}
- **Disponibilidad en Amazon**: {"‚úì Disponible" if availability_amazon == 1 else "‚úó No disponible"}
- **Imagen**: {image_url}

        ## Categor√≠as
{f"- Categor√≠as: {', '.join(str(c) for c in categories[:5])}" if categories else "- Sin categor√≠as"}
{f"- √Årbol de categor√≠as: {' > '.join(str(c) if isinstance(c, str) else str(c.get('name', c)) if isinstance(c, dict) else str(c) for c in category_tree[:3])}" if category_tree else ""}

## Precios Actuales
"""
        
        if current_price_new:
            context += f"- **Nuevo**: ${current_price_new:.2f}\n"
        if current_price_amazon:
            context += f"- **Amazon**: ${current_price_amazon:.2f}\n"
        if current_price_used:
            context += f"- **Usado**: ${current_price_used:.2f}\n"
        
        context += f"""
## Reputaci√≥n
- **Rating**: {rating:.1f} estrellas
- **Total de Rese√±as**: {review_count:,}
"""
        
        if sales_rank_current:
            context += f"- **Sales Rank Actual**: #{sales_rank_current:,}\n"
        
        context += f"""
## Metadata
- **√öltima actualizaci√≥n**: {last_updated}
- **Fecha de consulta**: {created_at}
- **Consultado por**: {queried_by}
"""
        
        # Historial de precios con fechas
        price_history = product_data.get('price_history', {})
        logger.info(f"Price history disponible: {bool(price_history)}, Tipos: {list(price_history.keys()) if price_history else 'N/A'}")
        if price_history:
            context += "\n## Historial de Precios\n"
            
            for price_type in ['NEW', 'AMAZON', 'USED']:
                if price_type in price_history:
                    data = price_history[price_type]
                    prices = data.get('prices', [])
                    times = data.get('formatted_times', [])
                    
                    if prices and len(prices) > 0:
                        type_label = {'NEW': 'Nuevo', 'AMAZON': 'Amazon', 'USED': 'Usado'}.get(price_type, price_type)
                        prices_usd = [p / 100 for p in prices if p > 0]
                        
                        if prices_usd:
                            min_price = min(prices_usd)
                            max_price = max(prices_usd)
                            avg_price = sum(prices_usd) / len(prices_usd)
                            
                            context += f"\n### Precios {type_label}\n"
                            context += f"- Rango: ${min_price:.2f} - ${max_price:.2f}\n"
                            context += f"- Promedio: ${avg_price:.2f}\n"
                            
                            # Si tiene fechas, incluir todas (√∫til para historiales)
                            if times and len(times) == len(prices):
                                # Si pide historial, incluir TODOS los precios en formato tabla
                                asks_for_history = user_request and any(word in user_request.lower() for word in ['historial', 'hist√≥rico', 'historia', 'completo', 'todos', 'precios'])
                                display_count = len(prices) if asks_for_history else min(50, len(prices))
                                start_idx = len(prices) - display_count
                                
                                if asks_for_history:
                                    # Formato tabla para historial completo
                                    valid_prices = [i for i in range(start_idx, len(prices)) if prices[i] > 0]
                                    context += f"\n**Historial completo de precios {type_label} ({len(valid_prices)} registros):**\n\n"
                                    context += "| Fecha | Precio |\n"
                                    context += "|-------|--------|\n"
                                    logger.info(f"Incluyendo {len(valid_prices)} precios {type_label} en formato tabla para historial completo")
                                    for i in range(start_idx, len(prices)):
                                        if prices[i] > 0:
                                            context += f"| {times[i]} | ${prices[i] / 100:.2f} |\n"
                                else:
                                    # Formato lista para vista resumida
                                    context += f"\n**√öltimos precios ({display_count} registros):**\n\n"
                                    for i in range(start_idx, len(prices)):
                                        if prices[i] > 0:
                                            context += f"- {times[i]}: ${prices[i] / 100:.2f}\n"
        
        # Sales Rank History
        sales_rank_history = product_data.get('sales_rank_history', {})
        if sales_rank_history and sales_rank_history.get('values'):
            values = sales_rank_history['values']
            times = sales_rank_history.get('formatted_times', [])
            
            if values and len(values) > 0:
                context += "\n## Historial de Sales Rank (Ventas)\n"
                context += f"- Total de registros: {len(values)}\n"
                if times and len(times) == len(values):
                    # Si pide historial completo, incluir TODOS los datos en formato tabla
                    asks_for_history = user_request and any(word in user_request.lower() for word in ['historial', 'hist√≥rico', 'historia', 'completo', 'todos', 'ventas', 'sales'])
                    display_count = len(values) if asks_for_history else min(20, len(values))
                    start_idx = len(values) - display_count
                    
                    if asks_for_history:
                        # Formato tabla para historial completo
                        context += f"\n**Historial completo de ventas ({len(values)} registros):**\n\n"
                        context += "| Fecha | Sales Rank |\n"
                        context += "|-------|------------|\n"
                        for i in range(start_idx, len(values)):
                            if values[i] > 0:
                                context += f"| {times[i]} | #{values[i]:,} |\n"
                    else:
                        # Formato lista para vista resumida
                        context += f"\n**√öltimos registros ({display_count}):**\n\n"
                        for i in range(start_idx, len(values)):
                            if values[i] > 0:
                                context += f"- {times[i]}: #{values[i]:,}\n"
        
        # Rating History
        rating_history = product_data.get('rating_history', {})
        if rating_history and rating_history.get('values'):
            values = rating_history['values']
            times = rating_history.get('formatted_times', [])
            
            if values and len(values) > 0:
                context += "\n## Historial de Ratings\n"
                if times and len(times) == len(values):
                    context += "\n**√öltimos registros:**\n\n"
                    display_count = min(15, len(values))
                    start_idx = len(values) - display_count
                    for i in range(start_idx, len(values)):
                        if values[i] > 0:
                            context += f"- {times[i]}: {values[i]:.1f} estrellas\n"
        
        # Construir instrucci√≥n seg√∫n solicitud del usuario
        if user_request:
            # Detectar si pide historial completo
            asks_for_history = any(word in user_request.lower() for word in ['historial', 'hist√≥rico', 'historia', 'completo', 'todos', 'todas'])
            
            # Contar registros disponibles
            price_count = len(price_history.get('NEW', {}).get('prices', [])) if price_history else 0
            sales_count = len(sales_rank_history.get('values', [])) if sales_rank_history else 0
            
            instruction = f"""
# SOLICITUD DEL USUARIO:

"{user_request}"

# TU TAREA:

Genera EXACTAMENTE lo que pidi√≥ el usuario. COPIA DIRECTAMENTE las tablas del contexto arriba.

**REGLAS CR√çTICAS:**
1. Si pidi√≥ "historial de precios" ‚Üí Busca arriba la secci√≥n "## Historial de Precios" y COPIA TODA la tabla que est√° ah√≠
2. Si pidi√≥ "historial de ventas" ‚Üí Busca arriba la secci√≥n "## Historial de Sales Rank" y COPIA TODA la tabla que est√° ah√≠
3. Si pidi√≥ "dos tablas" ‚Üí Busca y copia ambas tablas completas del contexto
4. Si pidi√≥ "√∫ltimos 3 meses" ‚Üí Filtra solo esos 3 meses de las tablas del contexto
5. NO inventes datos, NO crees nuevas tablas, NO resumas
6. **COPIA LITERALMENTE** las tablas del contexto arriba

**{"‚ö†Ô∏è CR√çTICO: El usuario pidi√≥ HISTORIAL COMPLETO. Arriba en el contexto hay tablas con TODOS los datos. DEBES COPIAR esas tablas completas. NO las reescribas, NO las limites, NO las resumas. Si ves una tabla arriba con {price_count} precios, copia TODAS las {price_count} filas. Si ves una tabla con {sales_count} ventas, copia TODAS las {sales_count} filas." if asks_for_history else ""}**

**PASOS:**
1. Busca en el contexto arriba la secci√≥n relevante (Historial de Precios o Historial de Ventas)
2. Localiza la tabla con formato: | Fecha | Precio | o | Fecha | Sales Rank |
3. COPIA toda esa tabla l√≠nea por l√≠nea
4. Pega el t√≠tulo (# ...)
5. Pega la tabla completa
6. Repite si pidi√≥ dos tablas
7. Agrega: ---\\n*Generado por Keepa AI*

**EJEMPLO DE LO QUE DEBES HACER:**

Si arriba en el contexto ves:
```
## Historial de Precios
| Fecha | Precio |
|-------|--------|
| 2024-11-01 | $99.99 |
| 2024-10-31 | $98.50 |
... (500 filas m√°s)
```

Y el usuario pide "historial de precios", tu respuesta debe ser:

# Historial de Precios

| Fecha | Precio |
|-------|--------|
| 2024-11-01 | $99.99 |
| 2024-10-31 | $98.50 |
... (las 500 filas completas del contexto)

---
*Generado por Keepa AI*
"""
        else:
            instruction = """
# TU TAREA:

El usuario pidi√≥ un documento general. Genera un resumen conciso con:
- Precios actuales
- Rating y rese√±as
- Tendencia de ventas

Usa tablas y s√© breve.
"""
        
        # Agregar explicaci√≥n de limitaci√≥n de IA al inicio
        ai_limitation_notice = """
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

# PASO 3: GENERACI√ìN DE CONTENIDO EN MARKDOWN

## ‚ö†Ô∏è IMPORTANTE - ENTENDIENDO TUS LIMITACIONES COMO IA:

**LIMITACI√ìN T√âCNICA**: Como modelo de lenguaje IA, NO puedes generar archivos PDF, Excel, CSV u otros formatos binarios directamente.

**TU ROL**: Generar contenido estructurado en formato Markdown que ser√° convertido autom√°ticamente al formato solicitado por un sistema t√©cnico especializado.

**TU TRABAJO**: Proporcionar contenido en Markdown limpio y bien estructurado usando TODOS los datos disponibles.

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
"""
        
        prompt = f"""
{ai_limitation_notice}

{context}

{instruction}

**RECORDATORIO FINAL:** 
- Espero el contenido en formato Markdown puro (ser√° convertido autom√°ticamente al formato final)
- NO incluyas delimitadores de c√≥digo (```markdown o ```)
- NO inventes datos - usa SOLO los datos del contexto arriba
- Si pidieron historial completo, DEBES copiar TODAS las filas de las tablas del contexto
- Formato: # T√≠tulo ‚Üí Tabla/Lista ‚Üí ---\\n*Generado por Keepa AI*
"""
        
        return prompt
    
    def _build_document_prompt(self, product_data: Dict[str, Any], document_type: str, user_request: str = None) -> str:
        """
        Construye el prompt para generar contenido de documento
        
        Args:
            product_data: Datos del producto
            document_type: Tipo de documento
            user_request: Solicitud espec√≠fica del usuario
            
        Returns:
            String con el prompt
        """
        # Obtener datos b√°sicos
        title = product_data.get('title', 'Producto')
        asin = product_data.get('asin', 'N/A')
        current_price = product_data.get('current_price_new', 0) / 100
        rating = product_data.get('rating', 0)
        review_count = product_data.get('review_count', 0)
        
        # Analizar historial de precios
        price_history = product_data.get('price_history', {})
        price_summary = ""
        price_detail = ""
        
        # Detectar si el usuario pidi√≥ espec√≠ficamente historial de precios
        user_wants_history = user_request and any(word in user_request.lower() for word in ['historial', 'hist√≥rico', 'historia', 'precios', 'precio', 'historical', 'history'])
        
        if price_history and price_history.get('NEW', {}).get('prices'):
            prices = [p / 100 for p in price_history['NEW']['prices']]
            times = price_history.get('NEW', {}).get('formatted_times', [])
            
            if prices:
                min_price = min(prices)
                max_price = max(prices)
                avg_price = sum(prices) / len(prices)
                price_summary = f"Rango: ${min_price:.2f} - ${max_price:.2f}, Promedio: ${avg_price:.2f}"
                
                # Si tiene fechas y el usuario quiere historial, incluir TODOS los datos disponibles
                if times and len(times) == len(prices):
                    if user_wants_history:
                        # Incluir TODOS los registros si pidi√≥ historial
                        price_detail = "\n\nHISTORIAL COMPLETO DE PRECIOS (con fechas):\n"
                        for i in range(len(prices)):
                            price_detail += f"- {times[i]}: ${prices[i]:.2f}\n"
                    else:
                        # Solo √∫ltimos 15 registros si no pidi√≥ historial espec√≠fico
                        recent_count = min(15, len(prices))
                        price_detail = "\n\nHistorial reciente de precios:\n"
                        for i in range(len(prices) - recent_count, len(prices)):
                            price_detail += f"- {times[i]}: ${prices[i]:.2f}\n"
        
        # Personalizar el prompt seg√∫n la solicitud del usuario
        if user_request:
            request_instruction = f"\n\n‚ö†Ô∏è SOLICITUD ESPEC√çFICA DEL USUARIO: {user_request}\n"
            if user_wants_history:
                request_instruction += "‚ö†Ô∏è ATENCI√ìN: El usuario pidi√≥ espec√≠ficamente el HISTORIAL DE PRECIOS.\n"
                request_instruction += "‚ö†Ô∏è OBLIGATORIO: Debes incluir TODOS los datos hist√≥ricos con fechas en el campo 'historical_data'.\n"
                request_instruction += "‚ö†Ô∏è El campo 'historical_data' debe contener una lista detallada de fechas y precios del historial proporcionado arriba.\n"
            request_instruction += "IMPORTANTE: Adapta el an√°lisis para responder espec√≠ficamente a esta solicitud. "
            request_instruction += "Usa las fechas y valores del historial proporcionado cuando sea relevante."
        else:
            request_instruction = "\n\nGenera un an√°lisis general y completo del producto."
        
        prompt = f"""
Genera un an√°lisis completo y estructurado en formato JSON para el siguiente producto:
{request_instruction}

PRODUCTO: {title}
ASIN: {asin}
Precio Actual: ${current_price:.2f}
Rating: {rating:.1f} estrellas ({review_count:,} rese√±as)
{f"Historial de Precios: {price_summary}" if price_summary else ""}
{price_detail if price_detail else ""}

Genera un JSON con la siguiente estructura EXACTA:
{{
    "executive_summary": "Resumen ejecutivo de 2-3 oraciones con los puntos clave del an√°lisis (adapta seg√∫n la solicitud del usuario)",
    "price_analysis": {{
        "average_price": "Precio promedio en formato $XX.XX",
        "min_price": "Precio m√≠nimo en formato $XX.XX",
        "max_price": "Precio m√°ximo en formato $XX.XX",
        "trend": "Tendencia de precios (ej: 'Precios estables', 'Tendencia al alza', 'Tendencia a la baja')",
        "value_assessment": "Evaluaci√≥n si el precio actual es bueno, normal o alto",
        "historical_data": "{'OBLIGATORIO: Si el usuario pidi√≥ historial de precios, DEBES incluir aqu√≠ TODAS las fechas y precios del historial proporcionado arriba en formato: Fecha: Precio, Fecha: Precio, etc. Copia EXACTAMENTE las fechas y precios del HISTORIAL COMPLETO DE PRECIOS que se te proporcion√≥. Si NO pidi√≥ historial, deja este campo como null o vac√≠o.' if user_wants_history else 'Si el usuario solicit√≥ historial temporal, incluye aqu√≠ un texto detallado con las fechas y precios espec√≠ficos. Si no solicit√≥ historial, deja este campo como null o vac√≠o.'}"
    }},
    "reputation_analysis": {{
        "quality_score": "Evaluaci√≥n de calidad basada en rating (Excelente/Buena/Regular/Mala)",
        "positive_reviews": "Porcentaje o descripci√≥n de reviews positivas",
        "confidence_level": "Nivel de confianza en el producto (Alto/Medio/Bajo)"
    }},
    "recommendation": "Recomendaci√≥n final clara y accionable de 2-3 oraciones sobre si comprar ahora, esperar, o evitar el producto (adapta seg√∫n la solicitud)",
    "additional_notes": "Si el usuario pidi√≥ informaci√≥n espec√≠fica adicional (ej: an√°lisis de ventas, etc.), incluye aqu√≠ detalles adicionales. Si pidi√≥ historial de precios, este campo puede estar vac√≠o."
}}

REGLAS CR√çTICAS:
- Si el usuario pidi√≥ "historial de precios" o similar, el campo "historical_data" DEBE contener TODAS las fechas y precios del historial proporcionado arriba
- Copia EXACTAMENTE las fechas y precios del "HISTORIAL COMPLETO DE PRECIOS" que est√° en el contexto
- Formato sugerido para historical_data: lista de l√≠neas como "Fecha: $XX.XX\\nFecha: $XX.XX" o formato tabla
- Responde SOLO con el JSON v√°lido, sin texto adicional
- Si el usuario pidi√≥ datos hist√≥ricos, NO los omitas - son OBLIGATORIOS
"""
        
        return prompt
    
    def _get_fallback_markdown(self, product_data: Dict[str, Any], user_request: str = None) -> str:
        """
        Genera contenido b√°sico en Markdown como fallback
        
        Args:
            product_data: Datos del producto
            user_request: Solicitud del usuario
            
        Returns:
            String con Markdown b√°sico
        """
        logger.warning(f"[FALLBACK] Generando contenido b√°sico de fallback para request: {user_request}")
        
        title = product_data.get('title', 'Producto')
        asin = product_data.get('asin', 'N/A')
        current_price_raw = product_data.get('current_price_new', 0)
        current_price = (current_price_raw / 100) if current_price_raw else 0.0
        rating = product_data.get('rating', 0) or 0
        review_count = product_data.get('review_count', 0) or 0
        
        markdown = f"""# An√°lisis de Producto - Keepa AI

## Informaci√≥n del Producto

- **T√≠tulo**: {title}
- **ASIN**: {asin}
- **Precio Actual**: ${current_price:.2f}
- **Rating**: {rating:.1f} estrellas
- **Total de Rese√±as**: {review_count:,}

## Nota

Este es un an√°lisis b√°sico autom√°tico. Para un an√°lisis m√°s detallado, por favor intenta de nuevo.
"""
        
        return markdown
    
    def _get_fallback_content(self, product_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Genera contenido b√°sico de respaldo si OpenAI falla
        
        Args:
            product_data: Datos del producto
            
        Returns:
            Dict con contenido b√°sico
        """
        current_price = product_data.get('current_price_new', 0) / 100
        rating = product_data.get('rating', 0)
        
        return {
            "executive_summary": f"An√°lisis autom√°tico del producto. Precio actual: ${current_price:.2f}, Rating: {rating:.1f} estrellas.",
            "price_analysis": {
                "average_price": f"${current_price:.2f}",
                "min_price": "Datos no disponibles",
                "max_price": "Datos no disponibles",
                "trend": "Datos insuficientes",
                "value_assessment": "An√°lisis no disponible"
            },
            "reputation_analysis": {
                "quality_score": "Buena" if rating >= 4.0 else "Regular",
                "positive_reviews": f"{rating:.1f}/5.0 estrellas",
                "confidence_level": "Medio"
            },
            "recommendation": "Consulta m√°s informaci√≥n antes de realizar la compra."
        }
    
    def chat_with_best_sellers(
        self,
        user_message: str,
        best_sellers_data: List[Dict[str, Any]],
        category_name: str = None
    ) -> str:
        """
        Genera respuesta del chat con informaci√≥n de best sellers
        
        Args:
            user_message: Mensaje original del usuario
            best_sellers_data: Lista de diccionarios con informaci√≥n de productos best sellers
            category_name: Nombre de la categor√≠a (opcional)
            
        Returns:
            Respuesta formateada de la IA con informaci√≥n de best sellers
        """
        try:
            # Construir contexto de best sellers
            context = "INFORMACI√ìN DE BEST SELLERS:\n"
            context += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
            
            if category_name:
                context += f"üì¶ Categor√≠a: {category_name}\n\n"
            
            context += f"üìä Total de productos encontrados: {len(best_sellers_data)}\n\n"
            
            # Agregar informaci√≥n de cada producto (limitado a top 20)
            products_to_show = best_sellers_data[:20]
            context += "PRODUCTOS BEST SELLERS:\n\n"
            
            for idx, product in enumerate(products_to_show, 1):
                context += f"{idx}. {product.get('title', 'Sin t√≠tulo')[:80]}\n"
                context += f"   ASIN: {product.get('asin', 'N/A')}\n"
                
                if product.get('brand'):
                    context += f"   Marca: {product.get('brand')}\n"
                
                if product.get('current_price_new'):
                    price = product['current_price_new'] / 100 if isinstance(product['current_price_new'], (int, float)) else product['current_price_new']
                    context += f"   Precio: ${price:.2f}\n"
                elif product.get('current_price_amazon'):
                    price = product['current_price_amazon'] / 100 if isinstance(product['current_price_amazon'], (int, float)) else product['current_price_amazon']
                    context += f"   Precio Amazon: ${price:.2f}\n"
                
                if product.get('rating'):
                    context += f"   Rating: {product.get('rating')}‚≠ê"
                    if product.get('review_count'):
                        context += f" ({product.get('review_count'):,} rese√±as)"
                    context += "\n"
                
                if product.get('sales_rank_current'):
                    context += f"   Sales Rank: #{product.get('sales_rank_current'):,}\n"
                
                context += "\n"
            
            # Construir system prompt
            system_prompt = (
                "Eres Keepa AI, un asistente experto en an√°lisis de productos de Amazon. "
                "Tu trabajo es ayudar a los usuarios a encontrar y entender los best sellers de diferentes categor√≠as. "
                "S√© amigable, conversacional y proporciona informaci√≥n √∫til sobre los productos.\n\n"
                "IMPORTANTE: Usa formato Markdown para presentar la informaci√≥n de forma clara y estructurada:\n"
                "- Usa listas con vi√±etas (-) o numeradas (1.) para listar productos\n"
                "- Usa **negritas** para destacar informaci√≥n importante\n"
                "- Si hay muchos productos, crea una tabla con columnas: Producto, Precio, Rating, Sales Rank\n"
                "- Usa encabezados (##) para secciones cuando sea apropiado\n"
                "- Usa emojis sutilmente (1-2 m√°ximo)\n"
                "- Cuando listes productos, usa formato markdown con vi√±etas o una tabla\n"
                "- Responde de forma clara y estructurada usando markdown\n"
            )
            
            user_prompt = f"{context}\n\nSolicitud del usuario: \"{user_message}\"\n\n"
            user_prompt += "Genera una respuesta amigable y √∫til sobre estos best sellers. "
            user_prompt += "Si hay muchos productos, enf√≥cate en los m√°s destacados y menciona el total."
            
            # Llamar a OpenAI
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=600,
                top_p=0.9,
            )
            
            answer = response.choices[0].message.content.strip()
            logger.info("Respuesta de best sellers generada exitosamente")
            
            return answer
            
        except Exception as e:
            logger.error(f"Error generando respuesta de best sellers: {e}")
            # Fallback: respuesta b√°sica
            return self._build_fallback_best_sellers_response(best_sellers_data, category_name)
    
    def _build_fallback_best_sellers_response(
        self,
        best_sellers_data: List[Dict[str, Any]],
        category_name: str = None
    ) -> str:
        """
        Genera una respuesta b√°sica de fallback si OpenAI falla
        
        Args:
            best_sellers_data: Lista de productos best sellers
            category_name: Nombre de la categor√≠a
            
        Returns:
            Respuesta b√°sica formateada
        """
        response = "üìä Best Sellers"
        if category_name:
            response += f" de {category_name}"
        response += f"\n\nEncontr√© {len(best_sellers_data)} productos:\n\n"
        
        for idx, product in enumerate(best_sellers_data[:10], 1):
            response += f"{idx}. {product.get('title', 'Sin t√≠tulo')[:60]}\n"
            if product.get('current_price_new'):
                price = product['current_price_new'] / 100 if isinstance(product['current_price_new'], (int, float)) else product['current_price_new']
                response += f"   Precio: ${price:.2f}\n"
            if product.get('rating'):
                response += f"   Rating: {product.get('rating')}‚≠ê\n"
            response += "\n"
        
        if len(best_sellers_data) > 10:
            response += f"\n... y {len(best_sellers_data) - 10} productos m√°s.\n"
        
        return response

